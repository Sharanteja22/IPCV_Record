{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYr82unu9k99"
      },
      "outputs": [],
      "source": [
        "#week1\n",
        "import scipy.linalg as la\n",
        "import numpy as np\n",
        "\n",
        "A=np.array([[1,2],[3,4]])\n",
        "B=np.array([[4,5],[6,7]])\n",
        "print(A)\n",
        "\n",
        "C=np.zeros([2,2])\n",
        "print(C)\n",
        "\n",
        "D=np.random.rand(2,2)\n",
        "print(D)\n",
        "\n",
        "E=np.eye(2,2)\n",
        "print(E)\n",
        "\n",
        "print(A+B)\n",
        "print(A-B)\n",
        "print(A*B)\n",
        "print(A@B)\n",
        "print(A/B)\n",
        "print(np.matmul(A,B))\n",
        "\n",
        "print(la.inv(A))\n",
        "\n",
        "print(A.T)\n",
        "print(np.transpose(A))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#week2\n",
        "import cv2\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=Image.open(\"/content/imag.jpg\")\n",
        "print(img.mode)\n",
        "print(img.palette)\n",
        "print(img.format)\n",
        "print(img.size)\n",
        "\n",
        "im=np.array(img)\n",
        "print(im)\n",
        "print(np.max(im))\n",
        "print(np.min(im))\n",
        "print(np.mean(im))\n",
        "\n",
        "cvimg = cv2.imread(\"/content/imag.jpg\")\n",
        "cv2_imshow(cvimg)\n",
        "\n",
        "negimg=255-cvimg\n",
        "cv2_imshow(negimg)\n",
        "\n",
        "neg=ImageOps.invert(img)\n",
        "ng=np.array(neg)\n",
        "cv2_imshow(ng)\n"
      ],
      "metadata": {
        "id": "LACouJeZ9mO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week4\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=cv2.imread(\"/content/imag.jpg\")\n",
        "blur=cv2.blur(img,(5,5))\n",
        "kernel=np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
        "sharp=cv2.filter2D(img,-1,kernel)\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "eq=cv2.equalizeHist(gray)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(blur)\n",
        "cv2_imshow(sharp)\n",
        "cv2_imshow(gray)\n",
        "cv2_imshow(eq)"
      ],
      "metadata": {
        "id": "YN55vPH69qfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week6\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=cv2.imread(\"/content/imag.jpg\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "_,thres=cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
        "\n",
        "data=img.reshape((-1,3)).astype(np.float32)\n",
        "_,lbl,ctr=cv2.kmeans(data,3,None,(3,10,1.0),5,cv2.KMEANS_RANDOM_CENTERS)\n",
        "kmeans=np.uint8(ctr)[lbl.flatten()].reshape(img.shape)\n",
        "\n",
        "cv2_imshow(thres)\n",
        "cv2_imshow(kmeans)\n",
        "\n"
      ],
      "metadata": {
        "id": "osjhczEU9svk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week7\n",
        "import cv2, numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(\"/content/imag.jpg\")\n",
        "\n",
        "data=img.reshape((-1,3)).astype(np.float32)\n",
        "_,lbl,ctr=cv2.kmeans(data,50,None,(3,10,1.0),5,cv2.KMEANS_RANDOM_CENTERS)\n",
        "com=np.uint8(ctr)[lbl.flatten()].reshape(img.shape)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(com)"
      ],
      "metadata": {
        "id": "DfAg00yo9tBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week8\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "img=cv2.imread(\"/content/imag.jpg\")\n",
        "kernel=np.ones((5,5))\n",
        "open=cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel)\n",
        "close=cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernel)\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(open)\n",
        "cv2_imshow(close)"
      ],
      "metadata": {
        "id": "fHH2eFV_9xZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week9\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "\n",
        "img=cv2.imread(\"/content/imag.jpg\")\n",
        "can=cv2.Canny(img,100,200)\n",
        "\n",
        "cv2_imshow(can)"
      ],
      "metadata": {
        "id": "hKpofZKn9zcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week10\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=cv2.imread(\"/content/imgg.jpg\")\n",
        "img=cv2.resize(img,None,fx=1.5,fy=1.5)\n",
        "\n",
        "hog=cv2.HOGDescriptor()\n",
        "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
        "\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "eq=cv2.equalizeHist(gray)\n",
        "\n",
        "boxes,wts=hog.detectMultiScale(eq,winStride=(4,4),padding=(16,16),scale=1.02)\n",
        "\n",
        "for (x,y,w,h) in boxes:\n",
        "  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255))\n",
        "cv2_imshow(img)\n",
        "print(len(boxes))"
      ],
      "metadata": {
        "id": "fYB7RwRT91Rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week11\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=cv2.imread(\"/content/imgg.jpg\")\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "sift=cv2.SIFT_create()\n",
        "\n",
        "key,des=sift.detectAndCompute(gray,None)\n",
        "im=cv2.drawKeypoints(img,key,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "cv2_imshow(im)\n",
        "print(len(key))"
      ],
      "metadata": {
        "id": "jn-4R2wF93nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week12\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img1 = cv2.imread(\"/content/imgg.jpg\")\n",
        "img2 = cv2.imread(\"/content/img2.jpg\")\n",
        "\n",
        "stitcher = cv2.Stitcher_create()\n",
        "\n",
        "(status, stitched) = stitcher.stitch([img1, img2])\n",
        "\n",
        "if status == cv2.Stitcher_OK:\n",
        "    cv2_imshow(stitched)\n",
        "else:\n",
        "    print(\"Error during stitching:\", status)\n"
      ],
      "metadata": {
        "id": "1IL_wqnp95Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week13\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/lbpcascades/lbpcascade_frontalface.xml -O lbpcascade_frontalface.xml\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img=cv2.imread('/content/imgg.jpg')\n",
        "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "lbp=cv2.CascadeClassifier('lbpcascade_frontalface.xml')\n",
        "faces=lbp.detectMultiScale(gray,1.1,5)\n",
        "\n",
        "for (x,y,w,h) in faces:\n",
        "  cv2.rectangle(img,(x,y),(x+w,y+h),(0,255))\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "dFy2B0WB97V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os, numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# !unzip dataset.zip -d /content/dataset\n",
        "\n",
        "cats=\"/content/dataset/dataset/cats\"\n",
        "dogs=\"/content/dataset/dataset/dogs\"\n",
        "\n",
        "imgs=[cv2.imread(os.path.join(p,f),0) for p,l in [(cats,0),(dogs,1)] for f in os.listdir(p)]\n",
        "y=[0]*len(os.listdir(cats))+[1]*len(os.listdir(dogs))\n",
        "\n",
        "sift=cv2.SIFT_create()\n",
        "D=[sift.detectAndCompute(i,None)[1] for i in imgs if i is not None]\n",
        "k=KMeans(50).fit(np.vstack([d for d in D if d is not None]))\n",
        "\n",
        "X=[]\n",
        "for i in imgs:\n",
        "    kp,d=sift.detectAndCompute(i,None)\n",
        "    if d is None: X.append(np.zeros(50)); continue\n",
        "    w=k.predict(d); X.append(np.bincount(w,minlength=50))\n",
        "X=np.array(X)\n",
        "\n",
        "clf=SVC().fit(X,y)\n",
        "t=cv2.imread('/content/cat4.jpg',0)\n",
        "w=k.predict(sift.detectAndCompute(t,None)[1])\n",
        "print(\"Dog üê∂\" if clf.predict([np.bincount(w,minlength=50)])[0] else \"Cat üê±\")\n"
      ],
      "metadata": {
        "id": "lt39eoaG97_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}